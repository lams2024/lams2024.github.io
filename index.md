---
title: Home
layout: page
---

# Bootstrap Workshop Template!

{% include figure.html img="uidaho-workshop.jpg" alt="intro image here" caption="Library workshop" width="75%" %}

While scientific and mathematical research endeavors typically transact over many data modalities, natural language is ultimately the primary medium by which researchers communicate ideas to each other. 
It is therefore strongly motivated to study if language agents (possibly augmented by other modalities) can accomplish useful research tasks, either autonomously or as a “co-pilot” for human researchers.

Recent work has shown that language model-based systems are competitive with other methods at tasks ranging from theorem proving to fundamental chemistry to robotic lab automation. 
On the other hand, significant gaps have been identified in their ability to reason mechanistically and reliably. 
In this workshop, we aim to discuss questions such as:
* At what tasks would language agents be most useful to the scientific community? This can include literature review tools, automated data analysis, experiment design, etc. Can we expect generalization across tasks?
* How can we ensure the reproducibility, trustworthiness, and performance of research language agents in science?
* How do we reconcile the open-endedness of most research tasks with the need for some "ground truth" for most conventional performance benchmarks?
* Which methods from RL and language model alignment research apply to this field, and what gaps still exist?
* Do agents need to implement effective world models in order to reason reliably?
* How do we mitigate compounding errors in long-running agents?
* How do we design environments for agents to (safely) interact with and learn from?


{% include toc.html %}

------

{% include template/credits.html %}
